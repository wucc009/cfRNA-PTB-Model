{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b8570-36ad-4bb4-825a-93db7571c5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T12:58:23.795223Z",
     "iopub.status.busy": "2026-01-28T12:58:23.794973Z",
     "iopub.status.idle": "2026-01-28T12:58:26.404082Z",
     "shell.execute_reply": "2026-01-28T12:58:26.403437Z",
     "shell.execute_reply.started": "2026-01-28T12:58:23.795206Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import joblib  \n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.stats import loguniform, uniform\n",
    "from minepy import MINE  \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from skrebate import ReliefF \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc828f-4ae8-4ecc-9376-d6c20757adbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:22:50.007666Z",
     "iopub.status.busy": "2026-01-12T11:22:50.007410Z",
     "iopub.status.idle": "2026-01-12T11:22:50.012631Z",
     "shell.execute_reply": "2026-01-12T11:22:50.012233Z",
     "shell.execute_reply.started": "2026-01-12T11:22:50.007647Z"
    }
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "mpl.rcParams['pdf.fonttype'] = 42 \n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c3c341-d08e-4846-99df-f3cba2967264",
   "metadata": {},
   "source": [
    "# Gene-pair modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d95470-339c-4790-b270-596197b60565",
   "metadata": {},
   "source": [
    "### 1. Gene-pair feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ab8d1-915a-42ec-87fe-624b8298f2d0",
   "metadata": {},
   "source": [
    "#### 1.1 Data import and matrix extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa5508-24a3-45a3-a096-65e5421688c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T05:52:02.972937Z",
     "iopub.status.busy": "2024-11-08T05:52:02.971389Z",
     "iopub.status.idle": "2024-11-08T05:52:05.750362Z",
     "shell.execute_reply": "2024-11-08T05:52:05.747712Z",
     "shell.execute_reply.started": "2024-11-08T05:52:02.972818Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/01_train_df.csv\", index_col=0)\n",
    "\n",
    "pos_set = data.filter(like='_PTB_')\n",
    "neg_set = data.filter(like='_nonPTB_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8065b4-9d1c-461e-93bd-904c98c7f1c6",
   "metadata": {},
   "source": [
    "#### 1.2 Sample size calculation and gene-pair matrix initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95e41c-ea16-4ebf-b947-d3d31baaa5b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T05:52:13.891257Z",
     "iopub.status.busy": "2024-11-08T05:52:13.889708Z",
     "iopub.status.idle": "2024-11-08T05:53:14.598443Z",
     "shell.execute_reply": "2024-11-08T05:53:14.596691Z",
     "shell.execute_reply.started": "2024-11-08T05:52:13.891136Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_nums = pos_set.shape[1]\n",
    "neg_nums = neg_set.shape[1]\n",
    "\n",
    "row_names = pos_set.index.tolist()\n",
    "combinations_list = list(combinations(row_names, 2))\n",
    "Gene_pairs = pd.DataFrame(combinations_list, columns=['Small_gene', 'Big_gene'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118fe4dd-75cf-4a6c-8630-29451fe9978a",
   "metadata": {},
   "source": [
    "#### 1.3 Compute GeneA < GeneB ratios for positive and negative groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6021b-3bf0-4d0e-9190-807ab09a2cfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T05:54:06.413527Z",
     "iopub.status.busy": "2024-11-08T05:54:06.412247Z",
     "iopub.status.idle": "2024-11-08T05:54:06.427949Z",
     "shell.execute_reply": "2024-11-08T05:54:06.425293Z",
     "shell.execute_reply.started": "2024-11-08T05:54:06.413398Z"
    }
   },
   "outputs": [],
   "source": [
    "def neg_calculate_counts(df):\n",
    "    diff = df - neg_set\n",
    "    neg_value = diff < 0\n",
    "    counts = neg_value.sum(axis=1)\n",
    "    \n",
    "    return counts\n",
    "    \n",
    "def pos_calculate_counts(df):\n",
    "    diff = df - pos_set\n",
    "    neg_value = diff < 0\n",
    "    counts = neg_value.sum(axis=1)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d95c87-ab6d-4afb-a2db-8af778e4f4a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:19:12.216349Z",
     "iopub.status.busy": "2024-11-08T06:19:12.214397Z",
     "iopub.status.idle": "2024-11-08T06:28:38.304056Z",
     "shell.execute_reply": "2024-11-08T06:28:38.296200Z",
     "shell.execute_reply.started": "2024-11-08T06:19:12.216238Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = neg_set.progress_apply(neg_calculate_counts, axis=1)\n",
    "rows, cols = np.triu_indices(counts.shape[0], k=1)\n",
    "neg_counts = counts.values[rows, cols]\n",
    "neg_ratios = neg_counts / neg_nums\n",
    "Gene_pairs = Gene_pairs.assign(Neg_ratio=neg_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034b43c-9dce-4867-b103-40b908670a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:12:44.965138Z",
     "iopub.status.busy": "2024-11-08T06:12:44.963634Z",
     "iopub.status.idle": "2024-11-08T06:13:19.143040Z",
     "shell.execute_reply": "2024-11-08T06:13:19.140772Z",
     "shell.execute_reply.started": "2024-11-08T06:12:44.965073Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = pos_set.progress_apply(pos_calculate_counts, axis=1)\n",
    "rows, cols = np.triu_indices(counts.shape[0], k=1)\n",
    "pos_counts = counts.values[rows, cols]\n",
    "pos_ratios = pos_counts / pos_nums\n",
    "Gene_pairs = Gene_pairs.assign(Pos_ratio=pos_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8a0ce-5bf6-46e8-a240-2efdc027fa98",
   "metadata": {},
   "source": [
    "#### 1.4 Calculate differences, standardize gene order by swapping negative pairs, sort by absolute difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5ea26-bf39-4791-a638-ecce14ba62e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:35:36.587336Z",
     "iopub.status.busy": "2024-11-08T06:35:36.585820Z",
     "iopub.status.idle": "2024-11-08T06:42:38.691694Z",
     "shell.execute_reply": "2024-11-08T06:42:38.689502Z",
     "shell.execute_reply.started": "2024-11-08T06:35:36.587271Z"
    }
   },
   "outputs": [],
   "source": [
    "Gene_pairs['diff_ratio'] = Gene_pairs['Neg_ratio'] - Gene_pairs['Pos_ratio']\n",
    "\n",
    "neg_rows = Gene_pairs['diff_ratio'] < 0\n",
    "Gene_pairs.loc[neg_rows, ['Small_gene', 'Big_gene']] = Gene_pairs.loc[neg_rows, ['Big_gene', 'Small_gene']].values\n",
    "\n",
    "Gene_pairs['diff_ratio'] = Gene_pairs['diff_ratio'].abs()\n",
    "Gene_pairs_sorted = Gene_pairs.sort_values(by='diff_ratio', ascending=False)\n",
    "Gene_pairs_sorted.drop(columns=['Neg_ratio', 'Pos_ratio'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f8227-333a-4c56-b48d-d2e6e4a85587",
   "metadata": {},
   "source": [
    "#### 1.5 Threshold-based gene-pair selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce1281-86e1-408b-a165-84201623318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_pairs = Gene_pairs_sorted[Gene_pairs_sorted['diff_ratio'] > 0.65]\n",
    "Gene_pairs.to_csv(\"./result/01_gene_pairs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d030f4-a852-4ccd-ba75-9e58bf5daae0",
   "metadata": {},
   "source": [
    "### 2. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d0af3-c13b-4f68-850a-1d06d8426ee5",
   "metadata": {},
   "source": [
    "#### 2.1 Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce0be92-e27b-438b-aca4-37f6245bab2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:31.442323Z",
     "iopub.status.busy": "2026-01-12T11:45:31.442076Z",
     "iopub.status.idle": "2026-01-12T11:45:31.447720Z",
     "shell.execute_reply": "2026-01-12T11:45:31.447256Z",
     "shell.execute_reply.started": "2026-01-12T11:45:31.442304Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_coding(df, feature_df, label, output_path):\n",
    "    encoding_data_index = feature_df.apply(lambda x: x.iloc[0] + \"|\" + x.iloc[1], axis=1)\n",
    "    encoding_data = pd.DataFrame(index=df.columns, columns=encoding_data_index)\n",
    "\n",
    "    for gene_name in encoding_data_index:\n",
    "        gene_name1, gene_name2 = gene_name.split(\"|\")\n",
    "        row1_data = df.loc[gene_name1]\n",
    "        row2_data = df.loc[gene_name2]\n",
    "        comparison_result = (row1_data < row2_data).astype(int) - (row1_data > row2_data).astype(int)\n",
    "        encoding_data[gene_name] = comparison_result\n",
    "    \n",
    "    encoding_data['Label'] = np.where(encoding_data.index.str.contains(label), 1, 0)\n",
    "\n",
    "    encoding_data.to_csv(output_path)\n",
    "    return encoding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e9702-2947-4f40-8ea5-7e5ef3d3ccb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T01:58:41.885890Z",
     "iopub.status.busy": "2024-12-28T01:58:41.885291Z",
     "iopub.status.idle": "2024-12-28T01:58:42.145068Z",
     "shell.execute_reply": "2024-12-28T01:58:42.144555Z",
     "shell.execute_reply.started": "2024-12-28T01:58:41.885839Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/01_train_df.csv\", index_col=0)\n",
    "feature_df = pd.read_csv(\"./result/01_gene_pairs.csv\")\n",
    "label = '_PTB_'\n",
    "output_path = \"./result/02_feature_coding_data.csv\"\n",
    "feature_coding(df, feature_df, label, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4d013-4ab2-4bad-aa91-5bd4ff61c8ed",
   "metadata": {},
   "source": [
    "#### 2.2 Model training and performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a140f90-79f0-486f-a5a6-303de1845e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T03:46:15.063690Z",
     "iopub.status.busy": "2024-12-28T03:46:15.063063Z",
     "iopub.status.idle": "2024-12-28T03:46:15.091946Z",
     "shell.execute_reply": "2024-12-28T03:46:15.091291Z",
     "shell.execute_reply.started": "2024-12-28T03:46:15.063639Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_selection(data, length, n_splits, selected_models, selected_base_models, output_path):    \n",
    "    length = math.ceil(length / 2)\n",
    "    \n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data['Label'].values\n",
    "    \n",
    "    models = {\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"LR\": LogisticRegression(random_state=42),\n",
    "        \"SVM\": SVC(probability=True, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, random_state=42),\n",
    "        \"RF\": RandomForestClassifier(random_state=42),\n",
    "        \"MLP\": MLPClassifier(random_state=42),\n",
    "        \"CNN\": PyTorchClassifier(input_dim=1, length=length, epochs=10, batch_size=16),\n",
    "    }\n",
    "    \n",
    "    if selected_base_models is None:\n",
    "        selected_base_models = list(models.keys())  \n",
    "\n",
    "    base_estimators = [(name, models[name]) for name in selected_base_models if name in models]\n",
    "    models[\"Stacking\"] = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(random_state=42))\n",
    "    models[\"Soft Voting\"] = VotingClassifier(estimators=base_estimators, voting='soft')\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scoring = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    \n",
    "    auc_scores = []\n",
    "    if selected_models is None:\n",
    "        for model_name, model in models.items():\n",
    "            try:\n",
    "                auc = cross_val_score(model, X, y, cv=cv, scoring=scoring).mean()\n",
    "                auc_scores.append({\"Model\": model_name, \"AUC\": auc})\n",
    "            except Exception as e:\n",
    "                print(f\"Error training model {model_name}: {e}\")\n",
    "        auc_scores = pd.DataFrame(auc_scores)\n",
    "        auc_scores = auc_scores.sort_values(by=\"AUC\", ascending=True)\n",
    "\n",
    "        auc_scores.to_csv(output_path, index=False)\n",
    "        return auc_scores\n",
    "\n",
    "    if isinstance(selected_models, str):\n",
    "        selected_models = [selected_models]\n",
    "    \n",
    "    selected_results = []\n",
    "    for model_name in selected_models:\n",
    "        if model_name in models:\n",
    "            model = models[model_name]\n",
    "            try:\n",
    "                auc = cross_val_score(model, X, y, cv=cv, scoring=scoring).mean()\n",
    "                selected_results.append({\"Model\": model_name, \"AUC\": auc})\n",
    "            except Exception as e:\n",
    "                selected_results.append({\"Model\": model_name, \"Error\": str(e)})\n",
    "        else:\n",
    "            selected_results.append({\"Model\": model_name, \"Error\": \"Model not found\"})\n",
    "    selected_results = pd.DataFrame(selected_results)\n",
    "    selected_results = selected_results.sort_values(by=\"AUC\", ascending=True)\n",
    "    \n",
    "    selected_results.to_csv(output_path, index=False)\n",
    "    return selected_results\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, length):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv1d(                        \n",
    "                in_channels = input_dim,\n",
    "                out_channels= input_dim * 32, \n",
    "                kernel_size = 3,\n",
    "                stride = 1,                   \n",
    "                padding = 1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size = 2, ceil_mode=True) \n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(input_dim*32*length, 1)     \n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)         \n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.out(x)           \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_dim, length, epochs, batch_size):\n",
    "        self.input_dim = input_dim\n",
    "        self.length = length\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = CNNModel(input_dim, length)\n",
    "        self.optimizer = optim.Adam(self.model.parameters())\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            for data, targets in loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.classes_ = torch.unique(torch.tensor(y)).numpy()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "        return torch.cat((1 - outputs, outputs), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527ff68-e569-4ef4-8ef2-17da70505d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T03:47:02.909585Z",
     "iopub.status.busy": "2024-12-28T03:47:02.908958Z",
     "iopub.status.idle": "2024-12-28T03:47:07.372010Z",
     "shell.execute_reply": "2024-12-28T03:47:07.371725Z",
     "shell.execute_reply.started": "2024-12-28T03:47:02.909534Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./result/02_feature_coding_data.csv\", index_col=0)\n",
    "length = 7\n",
    "n_splits = 5\n",
    "selected_models = ['KNN', 'Naive Bayes', 'LR', 'SVM', 'XGBoost', 'RF', 'Soft Voting', 'Stacking', 'MLP', 'CNN']\n",
    "output_path = './result/03_model_select.csv'\n",
    "selected_base_models = ['Naive Bayes', 'LR', 'SVM', 'XGBoost', 'RF', 'KNN']\n",
    "model_selection(data, length, n_splits, selected_models, selected_base_models, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799dba24-1031-4a17-9f5f-4ebcdc87b354",
   "metadata": {},
   "source": [
    "### 3. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186dc6bb-a8f1-410e-ad2a-2197958d6539",
   "metadata": {},
   "source": [
    "#### 3.1 Feature importance ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722853ad-4714-49f9-a181-d6a87370f152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T06:19:52.148902Z",
     "iopub.status.busy": "2024-12-28T06:19:52.148246Z",
     "iopub.status.idle": "2024-12-28T06:19:52.163332Z",
     "shell.execute_reply": "2024-12-28T06:19:52.162756Z",
     "shell.execute_reply.started": "2024-12-28T06:19:52.148855Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importance_rank(data, methods, output_path):\n",
    "    # MIC\n",
    "    def MIC_score(X, y):\n",
    "        mine = MINE(alpha=0.6, c=15)\n",
    "        mine.compute_score(X, y)\n",
    "        return mine.mic()\n",
    "    \n",
    "    def MIC_feature_importance_rank(df):\n",
    "        feature_list = []\n",
    "        MIC_list = []\n",
    "        selected_columns = df.columns[:-1]\n",
    "        y = df.iloc[:, -1]\n",
    "        \n",
    "        for column_name in selected_columns:\n",
    "            MIC = MIC_score(df[column_name], y)\n",
    "            feature_list.append(column_name)\n",
    "            MIC_list.append(MIC)\n",
    "            \n",
    "        MIC_order = pd.DataFrame({'MIC':feature_list, 'MIC_score':MIC_list})\n",
    "        MIC_order = MIC_order.sort_values(by=\"MIC_score\", ascending=False).reset_index(drop=True)\n",
    "        MIC_order = MIC_order.iloc[:, :1]\n",
    "        \n",
    "        return MIC_order\n",
    "    \n",
    "    # GBDT\n",
    "    def GBDT_feature_importance_rank(df):\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "        GBDT = GradientBoostingClassifier(random_state=42)\n",
    "        GBDT.fit(X, y)\n",
    "        GBDT_importances = GBDT.feature_importances_\n",
    "        GBDT_order = pd.DataFrame({'GBDT': X.columns, 'Importance': GBDT_importances})\n",
    "        GBDT_order = GBDT_order.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "        GBDT_order = GBDT_order.iloc[:, :1]\n",
    "        \n",
    "        return GBDT_order\n",
    "\n",
    "    # Relief\n",
    "    def Relief_feature_importance_rank(df):\n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df.iloc[:, -1].values\n",
    "        Relief = ReliefF(n_neighbors=10, n_features_to_select=X.shape[1])\n",
    "        Relief.fit(X, y)\n",
    "        Relief_importances = Relief.feature_importances_\n",
    "        feature_names = df.columns[:-1]\n",
    "        Relief_order = pd.DataFrame({'Relief':feature_names, 'Importance': Relief_importances})\n",
    "        Relief_order = Relief_order.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "        Relief_order = Relief_order.iloc[:, :1]\n",
    "\n",
    "        return Relief_order\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    if 'MIC' in methods:\n",
    "        MIC_order = MIC_feature_importance_rank(data)\n",
    "        result_df = pd.concat([result_df, MIC_order], axis=1)\n",
    "\n",
    "    if 'GBDT' in methods:\n",
    "        GBDT_order = GBDT_feature_importance_rank(data)\n",
    "        result_df = pd.concat([result_df, GBDT_order], axis=1)\n",
    "\n",
    "    if 'Relief' in methods:\n",
    "        Relief_order = Relief_feature_importance_rank(data)\n",
    "        result_df = pd.concat([result_df, Relief_order], axis=1)\n",
    "\n",
    "    if output_path:\n",
    "        result_df.to_csv(output_path, index=False)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003b2e0-8bfe-4aee-89cf-8e89010af04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T06:19:52.859367Z",
     "iopub.status.busy": "2024-12-28T06:19:52.858654Z",
     "iopub.status.idle": "2024-12-28T06:19:52.924942Z",
     "shell.execute_reply": "2024-12-28T06:19:52.924485Z",
     "shell.execute_reply.started": "2024-12-28T06:19:52.859319Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./result/02_feature_coding_data.csv\", index_col=0)\n",
    "methods = ['MIC', 'GBDT', 'Relief']\n",
    "output_path = False\n",
    "result = feature_importance_rank(data, methods, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738e787-b576-4d90-88a3-0c1f18f58be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T06:19:53.681456Z",
     "iopub.status.busy": "2024-12-28T06:19:53.680704Z",
     "iopub.status.idle": "2024-12-28T06:19:53.694506Z",
     "shell.execute_reply": "2024-12-28T06:19:53.693306Z",
     "shell.execute_reply.started": "2024-12-28T06:19:53.681400Z"
    }
   },
   "outputs": [],
   "source": [
    "# TSP score\n",
    "feature_df = pd.read_csv(\"./result/01_gene_pairs.csv\")\n",
    "result['TSP'] = feature_df.apply(lambda x: x.iloc[0] + \"|\" + x.iloc[1], axis=1)\n",
    "result.to_csv('./result/04_feature_importance_rank.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b43aef-dfe5-420b-8610-dc021f4cc1e0",
   "metadata": {},
   "source": [
    "#### 3.2 Incremental feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521abd63-da32-42b3-8383-1bc112af2dbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T06:13:53.508183Z",
     "iopub.status.busy": "2024-12-28T06:13:53.507588Z",
     "iopub.status.idle": "2024-12-28T06:13:53.529507Z",
     "shell.execute_reply": "2024-12-28T06:13:53.527952Z",
     "shell.execute_reply.started": "2024-12-28T06:13:53.508131Z"
    }
   },
   "outputs": [],
   "source": [
    "def incremental_feature_selection(data, feature_df, feature_num, model, n_splits, line_colors, result_path, plot_path):\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "    result_df = pd.DataFrame(columns=[\"Num_Features\"] + feature_df.columns.tolist())\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    \n",
    "    feature_range = range(1, feature_num + 1)\n",
    "\n",
    "    if line_colors is None:\n",
    "        line_colors = plt.cm.tab10(np.linspace(0, 1, len(feature_df.columns)))\n",
    "        \n",
    "    for num_features in tqdm(feature_range, desc=\"Incremental feature selection progress\"):\n",
    "        row = {\"Num_Features\": num_features}\n",
    "        \n",
    "        for method in feature_df.columns:\n",
    "            selected_features = feature_df[method].head(num_features)\n",
    "            X_selected = X[selected_features]\n",
    "            aucs = cross_val_score(model, X_selected, y, cv=cv, scoring=auc_scorer)\n",
    "            row[method] = np.mean(aucs)\n",
    "\n",
    "        result_df = pd.concat([result_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    \n",
    "    result_df.to_csv(result_path, index=False)\n",
    "    \n",
    "    plt.figure(figsize=(5, 3))\n",
    "    for i, method in enumerate(feature_df.columns): \n",
    "        plt.plot(result_df[\"Num_Features\"], result_df[method], label=method, marker='o', color=line_colors[i])\n",
    "\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(loc=\"lower right\", fontsize=10) \n",
    "    plt.xlabel(\"Number of Features\", fontsize=10)\n",
    "    plt.ylabel(\"AUC\", fontsize=10)\n",
    "    plt.xticks(np.arange(1, feature_num+1), np.arange(1, feature_num+1), fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "\n",
    "    plt.savefig(plot_path, format='pdf', dpi=300, bbox_inches='tight')  \n",
    "    plt.show()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ae93d-43e5-433f-aef1-a85f5d068a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T06:20:14.784565Z",
     "iopub.status.busy": "2024-12-28T06:20:14.783819Z",
     "iopub.status.idle": "2024-12-28T06:20:15.589904Z",
     "shell.execute_reply": "2024-12-28T06:20:15.589483Z",
     "shell.execute_reply.started": "2024-12-28T06:20:14.784509Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./result/02_feature_coding_data.csv\", index_col=0)\n",
    "feature_df = pd.read_csv(\"./result/04_feature_importance_rank.csv\")\n",
    "feature_num = 7\n",
    "model = GaussianNB()\n",
    "n_splits = 5\n",
    "line_colors = ['#576493', '#af454a', '#72a551', '#e69829']\n",
    "result_path = \"./result/05_incremental_feature_selection.csv\"\n",
    "plot_path = \"./result/06_incremental_feature_selection.pdf\"\n",
    "result = incremental_feature_selection(data, feature_df, feature_num, model, n_splits, line_colors, result_path, plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca3d45-19d4-49aa-9e9a-b423546d3cbc",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter optimization and model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b5f44-e268-48e8-89db-185d88d25f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:00:12.282453Z",
     "iopub.status.busy": "2024-11-22T09:00:12.282013Z",
     "iopub.status.idle": "2024-11-22T09:00:12.288323Z",
     "shell.execute_reply": "2024-11-22T09:00:12.287656Z",
     "shell.execute_reply.started": "2024-11-22T09:00:12.282432Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_optimized_model(data, feature_df, method, num_features, model, params, n_splits, n_iter, save_path):\n",
    "    selected_features = feature_df[method].head(num_features).tolist()\n",
    "    X = data[selected_features]\n",
    "    y = data.iloc[:, -1] \n",
    "    \n",
    "    scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=params,\n",
    "        scoring=scorer,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"Starting Randomized Search...\")\n",
    "    random_search.fit(X, y)\n",
    "    \n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "    print(f\"Best AUC score: {best_score}\")\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X, y)\n",
    "    \n",
    "    joblib.dump(best_model, save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return best_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e7fc3-7b8b-423c-8a99-be6d63361bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T06:21:26.696054Z",
     "iopub.status.busy": "2024-12-28T06:21:26.695424Z",
     "iopub.status.idle": "2024-12-28T06:21:33.406051Z",
     "shell.execute_reply": "2024-12-28T06:21:33.405402Z",
     "shell.execute_reply.started": "2024-12-28T06:21:26.696003Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./result/02_feature_coding_data.csv\", index_col=0)\n",
    "feature_df = pd.read_csv('./result/04_feature_importance_rank.csv')\n",
    "method = \"GBDT\"\n",
    "num_features = 5\n",
    "model = GaussianNB()\n",
    "params = {\n",
    "    'var_smoothing': loguniform(1e-9, 1e-2)\n",
    "}\n",
    "n_splits = 5\n",
    "n_iter = 10000\n",
    "save_path = \"./result/07_best_model.joblib\"\n",
    "result = train_optimized_model(data, feature_df, method, num_features, model, params, n_splits, n_iter, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ae3303b-7eb3-451e-9564-0efc0f534125",
   "metadata": {},
   "source": [
    "### 5. Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4808954-1474-4535-b00a-09487edc0f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:44.782962Z",
     "iopub.status.busy": "2026-01-12T11:45:44.782719Z",
     "iopub.status.idle": "2026-01-12T11:45:45.037698Z",
     "shell.execute_reply": "2026-01-12T11:45:45.037191Z",
     "shell.execute_reply.started": "2026-01-12T11:45:44.782943Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./data/02_test_df.csv\", index_col=0)\n",
    "E_valid_df = pd.read_csv(\"./data/03_E_valid_df.csv\", index_col=0)\n",
    "feature_df = pd.read_csv(\"./result/01_gene_pairs.csv\")\n",
    "label = '_PTB_'\n",
    "test_df_output_path = \"./result/08_test_feature_coding_data.csv\"\n",
    "E_valid_df_output_path = \"./result/09_val_feature_coding_data.csv\"\n",
    "feature_coding(test_df, feature_df, label, test_df_output_path)\n",
    "feature_coding(E_valid_df, feature_df, label, E_valid_df_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c1e5d-45fc-4b26-9381-bc374bf50837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:47:08.323498Z",
     "iopub.status.busy": "2026-01-12T11:47:08.323244Z",
     "iopub.status.idle": "2026-01-12T11:47:08.331899Z",
     "shell.execute_reply": "2026-01-12T11:47:08.331447Z",
     "shell.execute_reply.started": "2026-01-12T11:47:08.323478Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(train_data, test_data, val_data, feature_df, method, num_features, model_path, colors, save_path):\n",
    "    selected_features = feature_df[method].head(num_features).tolist()\n",
    "    X_train = train_data[selected_features]\n",
    "    y_train = train_data.iloc[:, -1] \n",
    "    X_test = test_data[selected_features]\n",
    "    y_test = test_data.iloc[:, -1] \n",
    "    X_val = val_data[selected_features]\n",
    "    y_val = val_data.iloc[:, -1] \n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    y_train_pred = model.predict_proba(X_train)[:, 1]  \n",
    "    y_test_pred = model.predict_proba(X_test)[:, 1]    \n",
    "    y_val_pred = model.predict_proba(X_val)[:, 1] \n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for y_true, y_pred, color, label in zip(\n",
    "        [y_train, y_test, y_val],\n",
    "        [y_train_pred, y_test_pred, y_val_pred],\n",
    "        colors,\n",
    "        ['Train', 'Test', 'Val']\n",
    "    ):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        auc_score = roc_auc_score(y_true, y_pred)\n",
    "        plt.plot(fpr, tpr, color=color, label=f'{label} AUC = {auc_score:.3f}', linewidth=2)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random\", linewidth=2)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(loc='lower right', fontsize=11)\n",
    "    plt.title(\"ROC Curve\", fontsize=16)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00973b01-4ca8-4e2d-8b6d-109f98ff7c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:47:53.411188Z",
     "iopub.status.busy": "2026-01-12T11:47:53.410955Z",
     "iopub.status.idle": "2026-01-12T11:47:56.733067Z",
     "shell.execute_reply": "2026-01-12T11:47:56.732579Z",
     "shell.execute_reply.started": "2026-01-12T11:47:53.411170Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./result/02_feature_coding_data.csv', index_col=0) \n",
    "test_data = pd.read_csv('./result/08_test_feature_coding_data.csv', index_col=0) \n",
    "val_data = pd.read_csv('./result/09_val_feature_coding_data.csv', index_col=0) \n",
    "feature_df = pd.read_csv('./result/04_feature_importance_rank.csv')\n",
    "method = 'GBDT'\n",
    "num_features = 5\n",
    "model_path = './result/07_best_model.joblib'\n",
    "colors = ['#226c87', '#f8d672', '#e48e11']\n",
    "save_path = './result/10_gene_pair_model_AUC.pdf'\n",
    "plot_roc_curve(train_data, test_data, val_data, feature_df, method, num_features, model_path, colors, plot_ci, n_bootstrap, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn (3.10.13)",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
